{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey_blue_path = 'data/grey_blue/'\n",
    "def clean_data(folder_path, columns_to_drop, fill_method):\n",
    "    columns_to_drop = columns_to_drop or []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        print(f\"Processing {filename}...\")\n",
    "        file = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        # Drop unwanted columns\n",
    "        df.drop(columns=columns_to_drop, axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "        # Drop the mouse movement (I only want the eye tracker data)\n",
    "        if \"Sensor\" in df.columns:\n",
    "            df = df[df[\"Sensor\"] != \"Mouse\"]\n",
    "\n",
    "        # Drop the first two rows (just starting the sensors):\n",
    "        df.drop([0, 1], inplace=True)\n",
    "\n",
    "        # Fill any NaN values with the preferred method\n",
    "        df.fillna(fill_method, inplace=True)\n",
    "\n",
    "        df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey_blue_path = 'data/grey_blue'\n",
    "columns_to_drop = [\"Unnamed: 0\", \"Recording timestamp\", \"Computer timestamp\", \"Project name\", \"Export date\", \"Participant name\", \"Recording name\", \"Recording date\", 'Recording start time UTC', 'Recording duration', 'Timeline name',\n",
    "       'Recording Fixation filter name', 'Recording software version',\n",
    "       'Recording resolution height', 'Recording resolution width',\n",
    "       'Recording monitor latency', 'Eyetracker timestamp', 'Presented Stimulus name',\n",
    "       'Presented Media name', 'Presented Media width', 'Event', 'Event value', 'Recording date UTC', 'Recording start time',\n",
    "       'Presented Media height', 'Presented Media position X (DACSpx)', 'Presented Media height',\n",
    "       'Presented Media position Y (DACSpx)', 'Original Media width',\n",
    "       'Original Media height', 'Mouse position X', 'Mouse position Y']\n",
    "fill_method = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing grey_blue_participant_10_trial_0.csv...\n",
      "Processing grey_blue_participant_10_trial_1.csv...\n",
      "Processing grey_blue_participant_10_trial_2.csv...\n",
      "Processing grey_blue_participant_10_trial_3.csv...\n",
      "Processing grey_blue_participant_14_trial_1.csv...\n",
      "Processing grey_blue_participant_14_trial_3.csv...\n",
      "Processing grey_blue_participant_18_trial_0.csv...\n",
      "Processing grey_blue_participant_18_trial_1.csv...\n",
      "Processing grey_blue_participant_18_trial_2.csv...\n",
      "Processing grey_blue_participant_18_trial_3.csv...\n",
      "Processing grey_blue_participant_24_trial_0.csv...\n",
      "Processing grey_blue_participant_24_trial_3.csv...\n",
      "Processing grey_blue_participant_26_trial_1.csv...\n",
      "Processing grey_blue_participant_26_trial_3.csv...\n",
      "Processing grey_blue_participant_28_trial_1.csv...\n",
      "Processing grey_blue_participant_28_trial_3.csv...\n",
      "Processing grey_blue_participant_2_trial_0.csv...\n",
      "Processing grey_blue_participant_2_trial_1.csv...\n",
      "Processing grey_blue_participant_2_trial_2.csv...\n",
      "Processing grey_blue_participant_2_trial_4.csv...\n",
      "Processing grey_blue_participant_30_trial_1.csv...\n",
      "Processing grey_blue_participant_30_trial_3.csv...\n",
      "Processing grey_blue_participant_32_trial_0.csv...\n",
      "Processing grey_blue_participant_34_trial_1.csv...\n",
      "Processing grey_blue_participant_34_trial_3.csv...\n",
      "Processing grey_blue_participant_36_trial_1.csv...\n",
      "Processing grey_blue_participant_38_trial_0.csv...\n",
      "Processing grey_blue_participant_38_trial_2.csv...\n",
      "Processing grey_blue_participant_40_trial_2.csv...\n",
      "Processing grey_blue_participant_40_trial_3.csv...\n",
      "Processing grey_blue_participant_42_trial_0.csv...\n",
      "Processing grey_blue_participant_42_trial_1.csv...\n",
      "Processing grey_blue_participant_44_trial_1.csv...\n",
      "Processing grey_blue_participant_44_trial_3.csv...\n",
      "Processing grey_blue_participant_46_trial_0.csv...\n",
      "Processing grey_blue_participant_46_trial_2.csv...\n",
      "Processing grey_blue_participant_48_trial_0.csv...\n",
      "Processing grey_blue_participant_48_trial_2.csv...\n",
      "Processing grey_blue_participant_4_trial_0.csv...\n",
      "Processing grey_blue_participant_4_trial_1.csv...\n",
      "Processing grey_blue_participant_4_trial_2.csv...\n",
      "Processing grey_blue_participant_4_trial_4.csv...\n",
      "Processing grey_blue_participant_4_trial_5.csv...\n",
      "Processing grey_blue_participant_4_trial_6.csv...\n",
      "Processing grey_blue_participant_4_trial_7.csv...\n",
      "Processing grey_blue_participant_4_trial_8.csv...\n",
      "Processing grey_blue_participant_50_trial_0.csv...\n",
      "Processing grey_blue_participant_50_trial_2.csv...\n",
      "Processing grey_blue_participant_52_trial_0.csv...\n",
      "Processing grey_blue_participant_52_trial_2.csv...\n",
      "Processing grey_blue_participant_54_trial_0.csv...\n",
      "Processing grey_blue_participant_54_trial_2.csv...\n",
      "Processing grey_blue_participant_56_trial_0.csv...\n",
      "Processing grey_blue_participant_56_trial_2.csv...\n",
      "Processing grey_blue_participant_58_trial_0.csv...\n",
      "Processing grey_blue_participant_58_trial_2.csv...\n",
      "Processing grey_blue_participant_60_trial_0.csv...\n",
      "Processing grey_blue_participant_60_trial_2.csv...\n",
      "Processing grey_blue_participant_6_trial_0.csv...\n",
      "Processing grey_blue_participant_6_trial_1.csv...\n",
      "Processing grey_blue_participant_6_trial_10.csv...\n",
      "Processing grey_blue_participant_6_trial_11.csv...\n",
      "Processing grey_blue_participant_6_trial_12.csv...\n",
      "Processing grey_blue_participant_6_trial_2.csv...\n",
      "Processing grey_blue_participant_6_trial_4.csv...\n",
      "Processing grey_blue_participant_6_trial_5.csv...\n",
      "Processing grey_blue_participant_6_trial_6.csv...\n",
      "Processing grey_blue_participant_6_trial_7.csv...\n",
      "Processing grey_blue_participant_6_trial_8.csv...\n",
      "Processing grey_blue_participant_6_trial_9.csv...\n",
      "Processing grey_blue_participant_8_trial_0.csv...\n",
      "Processing grey_blue_participant_8_trial_1.csv...\n",
      "Processing grey_blue_participant_8_trial_10.csv...\n",
      "Processing grey_blue_participant_8_trial_11.csv...\n",
      "Processing grey_blue_participant_8_trial_12.csv...\n",
      "Processing grey_blue_participant_8_trial_13.csv...\n",
      "Processing grey_blue_participant_8_trial_14.csv...\n",
      "Processing grey_blue_participant_8_trial_15.csv...\n",
      "Processing grey_blue_participant_8_trial_16.csv...\n",
      "Processing grey_blue_participant_8_trial_2.csv...\n",
      "Processing grey_blue_participant_8_trial_4.csv...\n",
      "Processing grey_blue_participant_8_trial_5.csv...\n",
      "Processing grey_blue_participant_8_trial_6.csv...\n",
      "Processing grey_blue_participant_8_trial_7.csv...\n",
      "Processing grey_blue_participant_8_trial_8.csv...\n",
      "Processing grey_blue_participant_8_trial_9.csv...\n"
     ]
    }
   ],
   "source": [
    "clean_data(grey_blue_path, columns_to_drop, fill_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taking care of variables**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/grey_blue/'\n",
    "for filename in os.listdir(path):\n",
    "    df = pd.read_csv(os.path.join(path, filename))\n",
    "    df = df.replace({',': '.'}, regex=True)\n",
    "\n",
    "    df[\"Sensor\"] = 1\n",
    "    df[\"Eye movement type\"] = df[\"Eye movement type\"].replace({\"EyesNotFound\": 0, \"Fixation\": 1, \"Saccade\": 2, \"Unclassified\": 3})\n",
    "    df['Validity left'] = df['Validity left'].replace({\"Valid\": 1, \"Invalid\": 0})\n",
    "    df['Validity right'] = df['Validity right'].replace({\"Valid\": 1, \"Invalid\": 0})\n",
    "\n",
    "\n",
    "    df.to_csv(os.path.join(path, filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
